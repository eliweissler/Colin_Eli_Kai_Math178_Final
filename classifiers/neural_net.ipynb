{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers, losses\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Data Crap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/collopa/Desktop/nonlinear/project/Colin_Eli_Kai_Math178_Final/data/train_vectors/train_features.pkl\", \"rb\") \\\n",
    "        as input_file:  train_features = pickle.load(input_file)\n",
    "    \n",
    "with open(\"/Users/collopa/Desktop/nonlinear/project/Colin_Eli_Kai_Math178_Final/data/train_vectors/train_labels.pkl\", \"rb\") \\\n",
    "    as input_file:  train_labels = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/collopa/Desktop/nonlinear/project/Colin_Eli_Kai_Math178_Final/data/test_vectors/test_features.pkl\", \"rb\") \\\n",
    "        as input_file:  test_features = pickle.load(input_file)\n",
    "    \n",
    "with open(\"/Users/collopa/Desktop/nonlinear/project/Colin_Eli_Kai_Math178_Final/data/test_vectors/test_labels.pkl\", \"rb\") \\\n",
    "    as input_file:  test_labels = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to reproduce results from \"Human Activity Recognition Based on Deep Learning Techniques\" by Manuel Gil-MartiÃÅn, et al. on their raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training set\n",
    "#acceleroation dataset\n",
    "train_f = np.array(train_features)\n",
    "train_f = train_f.reshape(len(train_f), 128, 12)\n",
    "train_a_data = train_f[:int(0.8 * len(train_f)),:, 0:3]\n",
    "\n",
    "train_a_truth = test_labels\n",
    "train_label_encoder = preprocessing.LabelEncoder()\n",
    "train_truth = train_label_encoder.fit_transform(train_a_truth)\n",
    "to_categorical(train_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4079 13460 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec = train_truth[:int(0.8 * len(train_truth))]\n",
    "\n",
    "#validation set\n",
    "val_a_data = train_a_data[int(0.8 * len(train_a_data)):]\n",
    "val_vec = train_truth[int(0.8 * len(train_a_data)):]\n",
    "\n",
    "print(len(train_vec), len(train_a_data), len(val_vec))\n",
    "\n",
    "#test set\n",
    "#acceleration dataset\n",
    "test_f = np.array(test_features)\n",
    "test_f = test_f.reshape(len(test_f), 128, 12)\n",
    "test_a_data = test_f[:,:, 0:3]\n",
    "test_a_truth = test_labels\n",
    "\n",
    "truth_label_encoder = preprocessing.LabelEncoder()\n",
    "test_vec = truth_label_encoder.fit_transform(test_a_truth)\n",
    "to_categorical(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (15,1),  \\\n",
    "                 input_shape = (128, 3,1), \n",
    "                 activation='relu')\n",
    "         )\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (8,1)) \n",
    "         )\n",
    "model.add(Conv2D(16, (10,1), \\\n",
    "                 activation='relu')\n",
    "         )\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (5,1))\n",
    "         )\n",
    "\n",
    "model.add(Dense(512, activation='relu' ))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model \n",
    "model.compile(loss = losses.categorical_crossentropy, \n",
    "              optimizer = optimizers.RMSprop(lr = 0.005), \n",
    "              metrics =['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_a_data, train_vec,\n",
    "          epochs = 15,\n",
    "          batch_size = 100,\n",
    "          validation_data = (val_a_data, val_vec))\n",
    "\n",
    "# evaluating and printing results \n",
    "score = model.evaluate(test_a_data, test_vec, verbose = 0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(val_a_data) == np.shape(val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
