As of 2019, it was estimated that 5 billion people have mobile devices and over half of these devices are smartphones. The sheer amount of data generated from these devices is enormous; most of them are equipped with accelerometer, gyroscopes, magnetometers, etc. The information from these sensors has enabled  the study of Human Activity Recognition (HAR). HAR has a variety of applications including healthcare, sports, continuous user authentication, and biometric key generation. The HAR data is often non-linear, but the approaches used for analysis do not take this into account.

There have been several papers published which utilize machine learning and deep learning techniques for HAR. Previous researchers used labeled accelerometer, gyroscope, magnetometer and electrocardiogram data for HAR \cite{masum2019human}. They compared the performance of three different classifiers (Random Forest, Support Vector Machine, Naive Bayes) and three different deep neural network architectures (Multilayer Perceptron, Deep Convolutional Neural Network and Long-Short Term Memory), and found that the deep neural networks performed the best. 

Previous researchers compared the performance of traditional machine learning methods (k-NN, SVM) to a residual network (ResNet) \cite{ferrari2019hand}. They used a variety of datasets, including Motion Sense \cite{malekzadeh2018protecting}. They used only the accelerometer data, and compared the classifier performance for using the raw data vs hand-crafted features. For the motion sense dataset, the hand-crafted features gave the best results for the classifier, but the ResNet still performed the best. ResNets allow for skipping between layers; these skips contain non-linearities, which are better able to represent the non-linear accelerometer data \cite{he2016deep}.

While both papers proved that deep learning architectures are the superior methods for HAR, neither of their traditional approaches accounted for the non-linear aspect of the accelerometer data. We are interested in improving the performance of traditional machine learning methods by accurately accounting for the the non-linearity of the data in a pre-processing step. In addition, we aim to combine multiple datasets for training and testing our model. If we are able to perform well, despite the fundamental differences in the datasets (sampling rate, different sensors, etc), then our model is quite robust.

We used the the Motion Sense dataset, which contains time-series data from accelerometers and gyroscope sensors on an iPhone 6. The data was collected at a rate of 50 Hz. There are 24 participants of a varying age, gender, weight, and height. The participants performed 6 different activities: walking, jogging, sitting, standing, walking up stairs, and walking down stairs. The accelerometer and gyroscope data are both made of 3 components along the x, y, and z axes. The acceleration data is split based on gravity and user acceleration, each of which has 3 additional components along each axis. The gyroscope data reports roll, pitch, and yaw as well as rotation rate along the three axes.

We initially wanted to confirm the results of training and testing on a raw dataset \cite{ferrari2019hand}. We preprocessed the data to be in the format at the paper. The data was broken into 128 dimensional segments; there are 128 samples of each sensor (for each axes) within a single feature vector. In addition, each segment has a 50\% overlap with the previous time series feature vector. We ensured that the feature vectors were only made from data that was recorded consecutively. These vectors were created for each activity for each user.

Our initial results were within 1 standard deviation of the results for the k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM)  \cite{ferrari2019hand}. There was no overlap between the feature vectors in the train and test datasets. 



